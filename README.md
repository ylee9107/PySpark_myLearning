# PySpark 

## Introduction:

This repo shows my learning and development process to further my understanding with using PySpark. These projects goes through the basics of PySpark such as dealing wwith RDDs and DataFrames or DAG visualisations (behind the scenes with the Spark Engine), to more intermediate and advanced topics like data preparation, using MLlib or the ML module (newer), structured streaming and GraphFrames. For these intermediate to advanced topics, the notebooks covers aspects such as obtaining the dataset and its cleaning, exploration & visualisation, feature engineering to building a ML model for predictions. Overall these projects as seen in thiss repo has further developed my understanding with the use of PySpark with my Data Science knowledge.

## Requirements:

The two main requirements to run PySpark:
1. Java
2. Python

Other requirements:
1. Scala
2. Maven
3. Livy
4. Hadoop
5. SparkMagic
6. Jupyter Extension - ipywidgets
7. Autoizwidget

