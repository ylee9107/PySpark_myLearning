{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark - Preparing the Data For Modeling\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project aims to explore the methods for preparing the dataset for modeling purposes. It is important to note that any dataset is dirty until proven otherwise and that it should be proven to be sufficiently clean before using it. However, no dataset can be entirely clean. Below will list some of the problems that can occur in a dataset. Majority of the time, 80% of the work is getting familiar and cleaning up the dataset. The remaining 20% would be building the model.\n",
    "\n",
    "For this project, the dataset used will only consist of 22 records, as this is to get a feel for data cleaning with PySpark and should be transferable to other datasets.\n",
    "\n",
    "## Problems that a Dataset can have:\n",
    "- __Duplicated Observations__: These types of duplication comes from systemic and operator's faults.\n",
    "- __Missing Observations__: These types of errors can come about due to sensor problems, data corruption or unwilling participant that would not provide answers.\n",
    "- __Anomalous Observations__: Observations that stands out when compared to the rest of the dataset. Like Outliers.\n",
    "- __Encoding__: This is when text fields are not normalised, in different languages, gibberish text inputs, or when date and date time fields were not encoded similarly.\n",
    "- __Untrustworthy answers__: These are true when it comes to surveys. When the response is a lie for any number of reasons. This type is much harder to work with and clean up.\n",
    "\n",
    "\n",
    "## Breakdown of this Notebook\n",
    "\n",
    "- Handling Duplicates in data records\n",
    "- Handling missing observations in dataset\n",
    "- Handling outliers\n",
    "- Exploring the descriptive statistics\n",
    "- Computing Correlations\n",
    "- Drawing Histograms to describe the data\n",
    "- Visualising the interactions between features\n",
    "\n",
    "\n",
    "## 1 PySpark Machine Configuration:\n",
    "\n",
    "Here it only uses two processing cores from the CPU, and it set up by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorCores': 4, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\n",
    "    \"executorCores\" : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Setup the Correct Directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the Path:\n",
    "path = '++++your working directory here++++/Datasets/'\n",
    "os.chdir(path)\n",
    "folder_pathway = os.getcwd()\n",
    "\n",
    "# print(folder_pathway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Create the Dataset: 22 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Dirty Dataset:\n",
    "dirty_data = spark.createDataFrame(\n",
    "    [(1,'Porsche','Boxster S','Turbo',2.5,4,22,None),\n",
    "     (2,'Aston Martin','Vanquish','Aspirated',6.0,12,16,None),\n",
    "     (3,'Porsche','911 Carrera 4S Cabriolet','Turbo',3.0,6,24,None),\n",
    "     (3,'General Motors','SPARK ACTIV','Aspirated',1.4,None,32,None),\n",
    "     (5,'BMW','COOPER S HARDTOP 2 DOOR','Turbo',2.0,4,26,None),\n",
    "     (6,'BMW','330i','Turbo',2.0,None,27,None),\n",
    "     (7,'BMW','440i Coupe','Turbo',3.0,6,23,None),\n",
    "     (8,'BMW','440i Coupe','Turbo',3.0,6,23,None),\n",
    "     (9,'Mercedes-Benz',None,None,None,None,27,None),\n",
    "     (10,'Mercedes-Benz','CLS 550','Turbo',4.7,8,21,79231),\n",
    "     (11,'Volkswagen','GTI','Turbo',2.0,4,None,None),\n",
    "     (12,'Ford Motor Company','FUSION AWD','Turbo',2.7,6,20,None),\n",
    "     (13,'Nissan','Q50 AWD RED SPORT','Turbo',3.0,6,22,None),\n",
    "     (14,'Nissan','Q70 AWD','Aspirated',5.6,8,18,None),\n",
    "     (15,'Kia','Stinger RWD','Turbo',2.0,4,25,None),\n",
    "     (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None),\n",
    "     (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None),\n",
    "     (18,'FCA US LLC','300','Aspirated',3.6,6,23,None),\n",
    "     (19,'Hyundai','G80 AWD','Turbo',3.3,6,20,None),\n",
    "     (20,'Hyundai','G80 AWD','Turbo',3.3,6,20,None),\n",
    "     (21,'BMW','X5 M','Turbo',4.4,8,18,121231),\n",
    "     (22,'GE','K1500 SUBURBAN 4WD','Aspirated',5.3,8,18,None) ],\n",
    "    schema = ['Id','Manufacturer','Model','EngineType','Displacement',\n",
    "     'Cylinders','FuelEconomy','MSRP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Id=1, Manufacturer='Porsche', Model='Boxster S', EngineType='Turbo', Displacement=2.5, Cylinders=4, FuelEconomy=22, MSRP=None)]"
     ]
    }
   ],
   "source": [
    "# Inspect:\n",
    "dirty_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Handling duplicates of data records:\n",
    "\n",
    "It can be very hard to spot duplicates of data and these happen all the time. PySpark DataFrame have a method to help remove these duplicates called .dropDuplicates() transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 21)"
     ]
    }
   ],
   "source": [
    "# First is to check for duplicated rows:\n",
    "dirty_data.count(), dirty_data.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From this \"(22, 21)\" output, it can be determined that there is one record of data that has a duplicate.\n",
    "\n",
    "#### To check which record it is:\n",
    "- First, use the .groupBy() function to define which of the dataset columns to aggregate. Here all the columns were chosen.\n",
    "- Next, count the number of times these records occur with the .count() function.\n",
    "- Next, use the .filter() method to select all of the rows in the dataset that occurs more than once.\n",
    "- Lastly, print these records out with the .show() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+\n",
      "| Id|Manufacturer|          Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|count|\n",
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+\n",
      "| 16|      Toyota|CAMRY HYBRID LE| Aspirated|         2.5|        4|         46|null|    2|\n",
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset for duplicates:\n",
    "(\n",
    "    dirty_data\n",
    "    .groupBy(dirty_data.columns)\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that __\"Id 16\"__ is the duplicate record.\n",
    "\n",
    "#### Next is to proceed in removing the duplicate row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove the duplicates:\n",
    "fully_removed_dat = dirty_data.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Duplicates: data IDs\n",
    "\n",
    "If the data is collected over time, it can be possible that the same data would be recorded with diffrent IDs. \n",
    "\n",
    "#### To check for Duplicate IDs:\n",
    "- First groupBy all the columns except for the \"Id\" column.\n",
    "- Next, is to count the number of records.\n",
    "- Next, is to extract the records that has a duplicate count. (\"count > 1\")\n",
    "- Finally, is to print out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+------------+---------+-----------+----+-----+\n",
      "|Manufacturer|     Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|count|\n",
      "+------------+----------+----------+------------+---------+-----------+----+-----+\n",
      "|         BMW|440i Coupe|     Turbo|         3.0|        6|         23|null|    2|\n",
      "|     Hyundai|   G80 AWD|     Turbo|         3.3|        6|         20|null|    2|\n",
      "+------------+----------+----------+------------+---------+-----------+----+-----+"
     ]
    }
   ],
   "source": [
    "# Inspect if the Dataset has duplicate IDs:\n",
    "(\n",
    "    fully_removed_dat\n",
    "    .groupBy( [col for col in fully_removed_dat.columns if col != 'Id'] )\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the count similar to the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 19)"
     ]
    }
   ],
   "source": [
    "# Save the data as a separate copy:\n",
    "no_ids_dat = (\n",
    "    fully_removed_dat\n",
    "    .select( [col for col in fully_removed_dat.columns if col != \"Id\"] )\n",
    ")\n",
    "\n",
    "# Compare the count:\n",
    "no_ids_dat.count(), no_ids_dat.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the output \"(21, 19)\", it shows that there are 4 duplicate records (or 2 duplicate IDs) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19"
     ]
    }
   ],
   "source": [
    "# Remove these duplicates:\n",
    "id_removed_dat = fully_removed_dat.dropDuplicates(\n",
    "    subset = [col for col in fully_removed_dat.columns if col != \"Id\"]\n",
    ")\n",
    "\n",
    "# Count the number of rows:\n",
    "id_removed_dat.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Duplicates: ID Collisions.\n",
    "\n",
    "At this point, after removing duplicates from the previous section, there may still be remaining duplicate IDs that are collisions.\n",
    "\n",
    "These may arise for multiple reasons such as:\n",
    "- Instrumental error\n",
    "- Insufficient data structure to store IDs data\n",
    "- IDs representing some hash function of the record elements\n",
    "- Arising collisions due to choice of hash function.\n",
    "\n",
    "### Import the required Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the dataset has Collisions:\n",
    "\n",
    "Rather than segmenting the operations as in the previous section, here, the code will execute all the required operations in one go.\n",
    "\n",
    "To do this:\n",
    "- Use the .count() method to count all the records that are of non-null values in a specified column.\n",
    "- Next, use the .countDistinct() method to return a distinct count of the vlaues in the specifed column. \n",
    "- Alias both with different names for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CountOfIDs|CountOfDistinctIDs|\n",
      "+----------+------------------+\n",
      "|        19|                18|\n",
      "+----------+------------------+"
     ]
    }
   ],
   "source": [
    "id_removed_dat.agg(\n",
    "    f.count('Id').alias('CountOfIDs'),\n",
    "    f.countDistinct('Id').alias('CountOfDistinctIDs')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, it can be seen that there are 2 records with the same IDs.\n",
    "\n",
    "### Check which IDs are duplicated in the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|count|\n",
      "+---+-----+\n",
      "|  3|    2|\n",
      "+---+-----+"
     ]
    }
   ],
   "source": [
    "(\n",
    "    id_removed_dat\n",
    "    .groupBy('Id')\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here it can be seen that ID 3 has duplicates.\n",
    "\n",
    "## Examine the row that is ID 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------------------+----------+------------+---------+-----------+----+\n",
      "| Id|  Manufacturer|               Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|\n",
      "+---+--------------+--------------------+----------+------------+---------+-----------+----+\n",
      "|  3|General Motors|         SPARK ACTIV| Aspirated|         1.4|     null|         32|null|\n",
      "|  3|       Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|         24|null|\n",
      "+---+--------------+--------------------+----------+------------+---------+-----------+----+"
     ]
    }
   ],
   "source": [
    "(\n",
    "    id_removed_dat\n",
    "    .filter('Id == 3')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here the records are not the same, however, they do share the same ID number (= 3).  To fix this, a new ID should be created that will be unique.\n",
    "\n",
    "### To do this:\n",
    "There is a PySpark SQL function called .monotonically_increasing_id() that will create a unique stream of IDs. \n",
    "\n",
    "Where it will:\n",
    "- Create an alias of the ID column \n",
    "\n",
    "NOTE: this method is good for dataset that are less than 1 billion partitions and the records have to be less than 8 billion recrods in each of the partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+------+\n",
      "|           Id|      Manufacturer|               Model|EngineType|Displacement|Cylinders|FuelEconomy|  MSRP|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+------+\n",
      "|   8589934592|    General Motors|         SPARK ACTIV| Aspirated|         1.4|     null|         32|  null|\n",
      "| 188978561024|     Mercedes-Benz|             CLS 550|     Turbo|         4.7|        8|         21| 79231|\n",
      "| 197568495616|     Mercedes-Benz|                null|      null|        null|     null|         27|  null|\n",
      "| 206158430208|Ford Motor Company|          FUSION AWD|     Turbo|         2.7|        6|         20|  null|\n",
      "| 438086664192|               BMW|COOPER S HARDTOP ...|     Turbo|         2.0|        4|         26|  null|\n",
      "| 523986010112|      Aston Martin|            Vanquish| Aspirated|         6.0|       12|         16|  null|\n",
      "| 721554505728|        Volkswagen|                 GTI|     Turbo|         2.0|        4|       null|  null|\n",
      "| 764504178688|               Kia|         Stinger RWD|     Turbo|         2.0|        4|         25|  null|\n",
      "| 919123001344|               BMW|                330i|     Turbo|         2.0|     null|         27|  null|\n",
      "| 944892805120|           Porsche|           Boxster S|     Turbo|         2.5|        4|         22|  null|\n",
      "| 970662608896|        FCA US LLC|                 300| Aspirated|         3.6|        6|         23|  null|\n",
      "|1030792151040|           Hyundai|             G80 AWD|     Turbo|         3.3|        6|         20|  null|\n",
      "|1039382085632|               BMW|          440i Coupe|     Turbo|         3.0|        6|         23|  null|\n",
      "|1116691496960|            Nissan|   Q50 AWD RED SPORT|     Turbo|         3.0|        6|         22|  null|\n",
      "|1211180777472|               BMW|                X5 M|     Turbo|         4.4|        8|         18|121231|\n",
      "|1331439861760|            Nissan|             Q70 AWD| Aspirated|         5.6|        8|         18|  null|\n",
      "|1606317768704|           Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|         24|  null|\n",
      "|1614907703296|            Toyota|     CAMRY HYBRID LE| Aspirated|         2.5|        4|         46|  null|\n",
      "|1700807049216|                GE|  K1500 SUBURBAN 4WD| Aspirated|         5.3|        8|         18|  null|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+------+"
     ]
    }
   ],
   "source": [
    "# Apply the fix:\n",
    "new_id_dat = (\n",
    "    id_removed_dat\n",
    "    .select(\n",
    "        [f.monotonically_increasing_id().alias('Id')] + \n",
    "        [col for col in id_removed_dat.columns if col != \"Id\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Inspect:\n",
    "new_id_dat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Handling Missing data observations:\n",
    "\n",
    "Missing data can be very common amongst datasets. Here, the dataset used will be \"new_id_dat\" from the previous section.\n",
    "\n",
    "## 5.1 Check the percentage of the data that is Missing:\n",
    "\n",
    "Each row and column will be checked for missing records. From these missing values, it will be determined what data is kept and what will be dropped, or potentially impute.\n",
    "\n",
    "### Calc the number of missing observations in the ROWS:\n",
    "\n",
    "To do this:\n",
    "- It is easier to work with RDDs and loop through each of the element to count the missing values.\n",
    "- First, access the RDD of the new_id_dat DataFrame and proceed with the .map() function.\n",
    "- In the .map() function, loop through each row to extract the 'Id' and count the missing values with \"sum([c == None for c in row])\"\n",
    "- The output of the .map() will be: Id, count of missing values.\n",
    "- Next, select mssing values that has a count of more than 1 with .filter() function.\n",
    "- Next, .collect() these records.\n",
    "- Lastly, create a simple DataFrame using the .orderBy() function to show the records that have missing values and in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|          Id|CountMissing|\n",
      "+------------+------------+\n",
      "|197568495616|           5|\n",
      "|  8589934592|           2|\n",
      "|919123001344|           2|\n",
      "|721554505728|           2|\n",
      "+------------+------------+"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.createDataFrame(\n",
    "        new_id_dat\n",
    "        .rdd\n",
    "        .map(\n",
    "            lambda row: (row['Id'], sum([c == None for c in row]))\n",
    "        )\n",
    "        .filter(lambda el: el[1] > 1)\n",
    "        .collect()\n",
    "        , ['Id', 'CountMissing']\n",
    "    )\n",
    "    .orderBy('CountMissing', ascending=False)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----+----------+------------+---------+-----------+----+\n",
      "|          Id| Manufacturer|Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|\n",
      "+------------+-------------+-----+----------+------------+---------+-----------+----+\n",
      "|197568495616|Mercedes-Benz| null|      null|        null|     null|         27|null|\n",
      "+------------+-------------+-----+----------+------------+---------+-----------+----+"
     ]
    }
   ],
   "source": [
    "# Inspect the records: that have the highest missing values.\n",
    "(\n",
    "    new_id_dat\n",
    "    .where('Id == 197568495616')\n",
    "    .show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above, it can be seen that Mercedes-Benz consists of a lot of Null values.\n",
    "\n",
    "### So, the next step:\n",
    "\n",
    "Would be to remove this record entirely. \n",
    "\n",
    "Note: The 'thresh = 4' is set to only remove records that consists of a minimum of 4 non-missing values. This particular record only has 3 useful pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merc_out = new_id_dat.dropna(thresh = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 18)"
     ]
    }
   ],
   "source": [
    "# Confirm by counts:\n",
    "new_id_dat.count(), merc_out.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----+----------+------------+---------+-----------+----+\n",
      "| Id|Manufacturer|Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|\n",
      "+---+------------+-----+----------+------------+---------+-----------+----+\n",
      "+---+------------+-----+----------+------------+---------+-----------+----+"
     ]
    }
   ],
   "source": [
    "# Inspect if it was really removed: should be a blank DataFrame.\n",
    "(\n",
    "    merc_out\n",
    "    .where('Id == 197568495616')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc the number of missing observations in the Columns:\n",
    "\n",
    "Here, the idea is to check if there are columns with low incidence of relevant information.\n",
    "\n",
    "To do this:\n",
    "- First, for the inner list that is \"(1 - (f.count(c) / f.count('*'))).alias(c + '_miss')\" and \"for c in merc_out.columns\", this is where a loop is used to go through all the columns in the merc_out DF, followed by a count on the number of non-missing values to be found in each of the columns. Next, is dividing it by the total count of all the rows. Then followed by subtracting this from 1, to get the percentage of missing values.\n",
    "\n",
    "   func can be seen as -> ( *[ (1 - (f.count(c) / f.count('*'))).alias(c + '_miss') for c in merc_out.columns] )\n",
    "   \n",
    "- Note, that no calc. is done yet as Python only stores the information as lists of objects/pointers. When the .agg() function is called, then it gets translated into PySpark's internal execution graph, and only gets executed once the .collect() action is called and executed.\n",
    "- The .collect() function will return a list of one element, that is a Row() object with aggregated information.\n",
    "- These Row() objects are then converted in dictionaries by using the .asDict() first before the items can be extracted by using the .items() functions. The results from this will be a list of tuples. \n",
    "- This list of tuples will have two elements, where the first one is the \"column name\" which is appened with \"_miss\" by use of the .alias() function. The second element is the percentage of the missing observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRP_miss 0.8888888888888888\n",
      "Cylinders_miss 0.11111111111111116\n",
      "FuelEconomy_miss 0.05555555555555558\n",
      "Id_miss 0.0\n",
      "Manufacturer_miss 0.0\n",
      "Model_miss 0.0\n",
      "EngineType_miss 0.0\n",
      "Displacement_miss 0.0"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(\n",
    "    merc_out\n",
    "    .agg(*[\n",
    "        (1 - (f.count(c) / f.count('*'))).alias(c + '_miss')\n",
    "        for c in merc_out.columns\n",
    "    ])\n",
    "    .collect()[0]\n",
    "    .asDict()\n",
    "    .items()\n",
    "    , key = lambda el: el[1]\n",
    "    , reverse = True\n",
    "):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRP_miss 0.8888888888888888\n",
      "Cylinders_miss 0.11111111111111116\n",
      "FuelEconomy_miss 0.05555555555555558\n",
      "Id_miss 0.0\n",
      "Manufacturer_miss 0.0\n",
      "Model_miss 0.0\n",
      "EngineType_miss 0.0\n",
      "Displacement_miss 0.0"
     ]
    }
   ],
   "source": [
    "# Another way to represent the above is:\n",
    "\n",
    "data = merc_out.agg(*[(1 - (f.count(c) / f.count('*'))).alias(c + '_miss') for c in merc_out.columns]).collect()[0].asDict().items()\n",
    "\n",
    "for k, v in sorted( data, key = lambda el: el[1], reverse = True ):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above, it can be seen that the MSRP column has a lot of missing values (at 88%). Therefore, this column can be dropped, as it provides no useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+\n",
      "|           Id|      Manufacturer|               Model|EngineType|Displacement|Cylinders|FuelEconomy|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+\n",
      "|   8589934592|    General Motors|         SPARK ACTIV| Aspirated|         1.4|     null|         32|\n",
      "| 188978561024|     Mercedes-Benz|             CLS 550|     Turbo|         4.7|        8|         21|\n",
      "| 206158430208|Ford Motor Company|          FUSION AWD|     Turbo|         2.7|        6|         20|\n",
      "| 438086664192|               BMW|COOPER S HARDTOP ...|     Turbo|         2.0|        4|         26|\n",
      "| 523986010112|      Aston Martin|            Vanquish| Aspirated|         6.0|       12|         16|\n",
      "| 721554505728|        Volkswagen|                 GTI|     Turbo|         2.0|        4|       null|\n",
      "| 764504178688|               Kia|         Stinger RWD|     Turbo|         2.0|        4|         25|\n",
      "| 919123001344|               BMW|                330i|     Turbo|         2.0|     null|         27|\n",
      "| 944892805120|           Porsche|           Boxster S|     Turbo|         2.5|        4|         22|\n",
      "| 970662608896|        FCA US LLC|                 300| Aspirated|         3.6|        6|         23|\n",
      "|1030792151040|           Hyundai|             G80 AWD|     Turbo|         3.3|        6|         20|\n",
      "|1039382085632|               BMW|          440i Coupe|     Turbo|         3.0|        6|         23|\n",
      "|1116691496960|            Nissan|   Q50 AWD RED SPORT|     Turbo|         3.0|        6|         22|\n",
      "|1211180777472|               BMW|                X5 M|     Turbo|         4.4|        8|         18|\n",
      "|1331439861760|            Nissan|             Q70 AWD| Aspirated|         5.6|        8|         18|\n",
      "|1606317768704|           Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|         24|\n",
      "|1614907703296|            Toyota|     CAMRY HYBRID LE| Aspirated|         2.5|        4|         46|\n",
      "|1700807049216|                GE|  K1500 SUBURBAN 4WD| Aspirated|         5.3|        8|         18|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+"
     ]
    }
   ],
   "source": [
    "# Drop the column \"MSRP\":\n",
    "no_MSRP = merc_out.select( [col for col in new_id_dat.columns if col != 'MSRP'] )\n",
    "\n",
    "# Inspect:\n",
    "no_MSRP.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Imputing the missing observations:\n",
    "\n",
    "This means the replacement of missing data with substituted values.\n",
    "\n",
    "There are __two__ ways to solve this:\n",
    "- One, Pass a value that every \"Null\" or \"None\" in the dataset will be replaced with.\n",
    "- Two, Pass a dictionary with different values in it for each of the column with missing records.\n",
    "\n",
    "In this example, the 2nd approach will be used. \n",
    "\n",
    "#### To do this: Specify a Ratio between the Fuel Economy and Displacement | Number of cyclinders and displacement.\n",
    "\n",
    "The formulas used to do these are the following:\n",
    "\n",
    "- To replace the missing values in the fuel economy -> \n",
    "    fuel_economy_mult = fuel_economy / (displacement * cylinders)\n",
    "    \n",
    "- To replace the missing calues in number of cylinders -> \n",
    "    cylinders_mult = cylinders / displacement\n",
    "\n",
    "These multipliers will be applied onto each row and taken as the average of these.\n",
    "    \n",
    "NOTE: these are not going to be accurate but serves the purpose. \n",
    "\n",
    "Once the formulas are applied, a dictionary can be created in Spark DataFrame is to use the .toPandss() function to convert the Spark DF to Pandas DF. This is then followed by a .to_dict() function to convert the data to a dictionary as proposed as the 2nd approach. \n",
    "\n",
    "The paramter that is \"records\" in the .to_dict() function, willcovert each row to a dictionary, where the key is the column name with the corresponding record value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Applying the formulas and create a Dictionary:\n",
    "\n",
    "multipliers_dict = (\n",
    "    no_MSRP\n",
    "    .agg(\n",
    "        f.mean(\n",
    "            f.col('FuelEconomy') / (f.col('Displacement') * f.col('Cylinders'))\n",
    "        ).alias('FuelEconomy'),\n",
    "        f.mean(\n",
    "            f.col('Cylinders') / f.col('Displacement')\n",
    "        ).alias('Cylinders')\n",
    "    )\n",
    ").toPandas().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FuelEconomy': 1.4957485048359973, 'Cylinders': 1.8353365984789105}"
     ]
    }
   ],
   "source": [
    "# Inspect:\n",
    "multipliers_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute the Dataset with the created Dictionary above:\n",
    "\n",
    "To do this:\n",
    "- First, convert the original data to reflect the ratios specified earlier.\n",
    "- Apply the multipliers_dict to fill in the missing values in the data.\n",
    "- Lastly, revert the columns back to their orignal state.\n",
    "\n",
    "The .withColumn() function overwrites the origninal column names.\n",
    "\n",
    "Source: https://sparkbyexamples.com/spark/spark-dataframe-withcolumn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputed_dat = (\n",
    "    no_MSRP\n",
    "    .withColumn('FuelEconomy', f.col('FuelEconomy') / f.col('Displacement') / f.col('Cylinders'))\n",
    "    .withColumn('Cylinders', f.col('Cylinders') / f.col('Displacement'))\n",
    "    .fillna(multipliers_dict)\n",
    "    .withColumn('Cylinders', (f.col('Cylinders') * f.col('Displacement')).cast('integer') )\n",
    "    .withColumn('FuelEconomy', f.col('FuelEconomy') * f.col('Displacement') * f.col('Cylinders'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+\n",
      "|           Id|      Manufacturer|               Model|EngineType|Displacement|Cylinders|       FuelEconomy|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+\n",
      "|   8589934592|    General Motors|         SPARK ACTIV| Aspirated|         1.4|        2| 4.188095813540793|\n",
      "| 188978561024|     Mercedes-Benz|             CLS 550|     Turbo|         4.7|        8|              21.0|\n",
      "| 206158430208|Ford Motor Company|          FUSION AWD|     Turbo|         2.7|        5|16.666666666666668|\n",
      "| 438086664192|               BMW|COOPER S HARDTOP ...|     Turbo|         2.0|        4|              26.0|\n",
      "| 523986010112|      Aston Martin|            Vanquish| Aspirated|         6.0|       12|              16.0|\n",
      "| 721554505728|        Volkswagen|                 GTI|     Turbo|         2.0|        4|11.965988038687978|\n",
      "| 764504178688|               Kia|         Stinger RWD|     Turbo|         2.0|        4|              25.0|\n",
      "| 919123001344|               BMW|                330i|     Turbo|         2.0|        3| 8.974491029015983|\n",
      "| 944892805120|           Porsche|           Boxster S|     Turbo|         2.5|        4|              22.0|\n",
      "| 970662608896|        FCA US LLC|                 300| Aspirated|         3.6|        6|              23.0|\n",
      "|1030792151040|           Hyundai|             G80 AWD|     Turbo|         3.3|        6|              20.0|\n",
      "|1039382085632|               BMW|          440i Coupe|     Turbo|         3.0|        6|23.000000000000004|\n",
      "|1116691496960|            Nissan|   Q50 AWD RED SPORT|     Turbo|         3.0|        6|21.999999999999996|\n",
      "|1211180777472|               BMW|                X5 M|     Turbo|         4.4|        8|              18.0|\n",
      "|1331439861760|            Nissan|             Q70 AWD| Aspirated|         5.6|        8|              18.0|\n",
      "|1606317768704|           Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|              24.0|\n",
      "|1614907703296|            Toyota|     CAMRY HYBRID LE| Aspirated|         2.5|        4|              46.0|\n",
      "|1700807049216|                GE|  K1500 SUBURBAN 4WD| Aspirated|         5.3|        8|              18.0|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+"
     ]
    }
   ],
   "source": [
    "# Inspect the DF:\n",
    "imputed_dat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The resulting values found in the cylinders and fuel economy columns are not completely accurate, however, they aare still better than just replacing them with predefined values.\n",
    "\n",
    "\n",
    "## 6 Handling Outliers in the Dataset:\n",
    "\n",
    "Observations that can be found at the long tail(s) of a data distribution are considered to be __Outliers__. \n",
    "\n",
    "### Mathematically define and Outlier:\n",
    "\n",
    "For a point (P) that meets the following criteria that is:\n",
    "   \n",
    "   - $Q^{1}$ - 1.5*IQR $\\le$ P $\\le$ $Q^{3}$ + 1.5 * IQR\n",
    "   - where IQR is $Q^{3}$ - $Q^{1}$\n",
    "\n",
    "Won't be considered and Outlier, however, any point (P) that appears __out__ of this criteria is considered to be an __Outlier__.\n",
    "\n",
    "## 6.1 Find the Outliers:\n",
    "\n",
    "To do this:\n",
    "\n",
    "#### First, Calculate the ranges.\n",
    "Taking only the numerical variables such as the displacement, cylinders and fuel economy. A For-loop is used to calculate the 1st and 3rd quantiles with the .approxQuantile() function. There are three parameters for this function, where the first is the column name, the second is a float (or a list of floats) of quantiles to compute, the third is a number that specifies the target precision, and the value of 0 should be avoided. This function returns a list of two values that are the upper and lower quantiles. \n",
    "\n",
    "Next, it proceeds to calculate the IQR using the computed quantiles. Then it will append the \"(feature_name, [lower_bound, upper_bound))\" to the cut_off_point list. Finally, it will convert this into a dictionary.\n",
    "\n",
    "\n",
    "#### Second, Find the outliers.\n",
    "\n",
    "To find the outliers, select the ID columns and proceed to loop through the features, checking whether it fall outside of the calculated bounds that is the cut_off_points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the ranges:\n",
    "features = ['Displacement', 'Cylinders', 'FuelEconomy']\n",
    "quantiles = [0.25, 0.75]\n",
    "\n",
    "cut_off_points = []\n",
    "\n",
    "for i in features:\n",
    "    quants = imputed_dat.approxQuantile(i, quantiles, 0.05)\n",
    "    IQR = quants[1] - quants[0]\n",
    "    cut_off_points.append( (i, [quants[0] - 1.5 * IQR, quants[1] + 1.5 * IQR]))\n",
    "    \n",
    "# Save to dict:\n",
    "cut_off_points = dict(cut_off_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Displacement': [-1.6000000000000005, 8.0], 'Cylinders': [-2.0, 14.0], 'FuelEconomy': [7.166666666666664, 32.50000000000001]}"
     ]
    }
   ],
   "source": [
    "# Inspect:\n",
    "cut_off_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the Outliers:\n",
    "outliers_DF = imputed_dat.select(*['Id'] + [\n",
    "    (\n",
    "        (imputed_dat[f] < cut_off_points[f][0]) | (imputed_dat[f] > cut_off_points[f][1])\n",
    "    ).alias(f + '_o') for f in features\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+-------------+\n",
      "|           Id|Displacement_o|Cylinders_o|FuelEconomy_o|\n",
      "+-------------+--------------+-----------+-------------+\n",
      "|   8589934592|         false|      false|         true|\n",
      "| 188978561024|         false|      false|        false|\n",
      "| 206158430208|         false|      false|        false|\n",
      "| 438086664192|         false|      false|        false|\n",
      "| 523986010112|         false|      false|        false|\n",
      "| 721554505728|         false|      false|        false|\n",
      "| 764504178688|         false|      false|        false|\n",
      "| 919123001344|         false|      false|        false|\n",
      "| 944892805120|         false|      false|        false|\n",
      "| 970662608896|         false|      false|        false|\n",
      "|1030792151040|         false|      false|        false|\n",
      "|1039382085632|         false|      false|        false|\n",
      "|1116691496960|         false|      false|        false|\n",
      "|1211180777472|         false|      false|        false|\n",
      "|1331439861760|         false|      false|        false|\n",
      "|1606317768704|         false|      false|        false|\n",
      "|1614907703296|         false|      false|         true|\n",
      "|1700807049216|         false|      false|        false|\n",
      "+-------------+--------------+-----------+-------------+"
     ]
    }
   ],
   "source": [
    "# Inspect:\n",
    "outliers_DF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at the table above, it can be seen that there are __2__ outliers in the FuelEconomy_o column. \n",
    "\n",
    "## 6.2 Check these records that are outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+---------------+-----------------+\n",
      "|           Id|  Manufacturer|          Model|      FuelEconomy|\n",
      "+-------------+--------------+---------------+-----------------+\n",
      "|   8589934592|General Motors|    SPARK ACTIV|4.188095813540793|\n",
      "|1614907703296|        Toyota|CAMRY HYBRID LE|             46.0|\n",
      "+-------------+--------------+---------------+-----------------+"
     ]
    }
   ],
   "source": [
    "# Join the imputed DF with the Outliers DF:\n",
    "without_outliers_found = imputed_dat.join(outliers_DF, on='Id')\n",
    "\n",
    "# Filter out for outlier records only:\n",
    "(\n",
    "    without_outliers_found\n",
    "    .filter('FuelEconomy_o')\n",
    "    .select('Id', 'Manufacturer', 'Model', 'FuelEconomy')\n",
    "    .show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It can be seen that the two outliers are Model: Spark Activ and Camry Hybrid LE.\n",
    "\n",
    "Here, the Spark Activ presents with a very LOW fuel economy, and checking the imputed_dat table, it presents with a small engine (1.4 litres and 2 cylinders), which means that having this low fuel economy is not possible. Therefore, logically, this error have arrised due to the imputation logic implemented earlier. \n",
    "\n",
    "Further, the Camry is a hybrid vehicle, and checking the imputed_dat table, it can be said that it does stand out when compared to the larger engine size with turbochargers. \n",
    "\n",
    "NOTE: when building a machine learning model, having these outliers can present with untrustworthy results and the model wont be able to generalise well enough. \n",
    "\n",
    "Therefore it is advisable to REMOVE these records from the dataset. (or make a change in the imputation logic).\n",
    "\n",
    "## 6.3 Remove the Outliers:\n",
    "\n",
    "Here it will filter out all of the records that are not in the column \"FuelEconomy_o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+\n",
      "|           Id|      Manufacturer|               Model|EngineType|Displacement|Cylinders|       FuelEconomy|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+\n",
      "| 919123001344|               BMW|                330i|     Turbo|         2.0|        3| 8.974491029015983|\n",
      "|1211180777472|               BMW|                X5 M|     Turbo|         4.4|        8|              18.0|\n",
      "| 188978561024|     Mercedes-Benz|             CLS 550|     Turbo|         4.7|        8|              21.0|\n",
      "| 970662608896|        FCA US LLC|                 300| Aspirated|         3.6|        6|              23.0|\n",
      "|1331439861760|            Nissan|             Q70 AWD| Aspirated|         5.6|        8|              18.0|\n",
      "|1116691496960|            Nissan|   Q50 AWD RED SPORT|     Turbo|         3.0|        6|21.999999999999996|\n",
      "| 944892805120|           Porsche|           Boxster S|     Turbo|         2.5|        4|              22.0|\n",
      "| 523986010112|      Aston Martin|            Vanquish| Aspirated|         6.0|       12|              16.0|\n",
      "| 721554505728|        Volkswagen|                 GTI|     Turbo|         2.0|        4|11.965988038687978|\n",
      "|1700807049216|                GE|  K1500 SUBURBAN 4WD| Aspirated|         5.3|        8|              18.0|\n",
      "| 206158430208|Ford Motor Company|          FUSION AWD|     Turbo|         2.7|        5|16.666666666666668|\n",
      "| 764504178688|               Kia|         Stinger RWD|     Turbo|         2.0|        4|              25.0|\n",
      "|1030792151040|           Hyundai|             G80 AWD|     Turbo|         3.3|        6|              20.0|\n",
      "|1606317768704|           Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|              24.0|\n",
      "| 438086664192|               BMW|COOPER S HARDTOP ...|     Turbo|         2.0|        4|              26.0|\n",
      "|1039382085632|               BMW|          440i Coupe|     Turbo|         3.0|        6|23.000000000000004|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+"
     ]
    }
   ],
   "source": [
    "no_outliers_dat = (\n",
    "    without_outliers_found\n",
    "    .filter('!FuelEconomy_o')\n",
    "    .select(imputed_dat.columns)\n",
    ")\n",
    "\n",
    "# Inspect:\n",
    "no_outliers_dat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Exploring Descriptive Statistics:\n",
    "\n",
    "Descriptive Statistics are very useful and considered to be fundamental measures to perform/calculate on the data. \n",
    "\n",
    "The method applied here is the \".describe()\" method, where:\n",
    "- It takes a list of columns (\"features\") to calculate the statistics on and returns a DataFrame of the statistical description.\n",
    "- These can include: count, mean, standard deviation, minimum value and maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------------------+\n",
      "|summary|     Displacement|        Cylinders|       FuelEconomy|\n",
      "+-------+-----------------+-----------------+------------------+\n",
      "|  count|               16|               16|                16|\n",
      "|   mean|          3.44375|            6.125|19.600446608398165|\n",
      "| stddev|1.354975399530683|2.276693508870558| 4.666647767373751|\n",
      "|    min|              2.0|                3| 8.974491029015983|\n",
      "|    max|              6.0|               12|              26.0|\n",
      "+-------+-----------------+-----------------+------------------+"
     ]
    }
   ],
   "source": [
    "# Apply the func:\n",
    "descriptive_stats_DF = no_outliers_dat.describe(features)\n",
    "\n",
    "# Inspect:\n",
    "descriptive_stats_DF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 16 records in total and from the description, it can be seen that the data is skewed towards vehicles with larger engine sizes. These are represented with a mean displacement of 3.44 and 6 cylinders. The mean fuel economy is 19.6 mpg.\n",
    "\n",
    "## 7.1 Calculate Descriptive Statistics: without passing a list of columns (\"features\")\n",
    "\n",
    "Here Pyspark will return statistics for each of the columns in the DataFrame.\n",
    "\n",
    "It can be seen that even the string values are calculated on, this means that the statistics for these columns are not viable for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------+-----+----------+-----------------+-----------------+------------------+\n",
      "|summary|                  Id|Manufacturer|Model|EngineType|     Displacement|        Cylinders|       FuelEconomy|\n",
      "+-------+--------------------+------------+-----+----------+-----------------+-----------------+------------------+\n",
      "|  count|                  16|          16|   16|        16|               16|               16|                16|\n",
      "|   mean|    9.19659872256E11|        null|300.0|      null|          3.44375|            6.125|19.600446608398165|\n",
      "| stddev|4.396778949583304E11|        null|  NaN|      null|1.354975399530683|2.276693508870558| 4.666647767373751|\n",
      "|    min|        188978561024|Aston Martin|  300| Aspirated|              2.0|                3| 8.974491029015983|\n",
      "|    max|       1700807049216|  Volkswagen| X5 M|     Turbo|              6.0|               12|              26.0|\n",
      "+-------+--------------------+------------+-----+----------+-----------------+-----------------+------------------+"
     ]
    }
   ],
   "source": [
    "# Apply the func:\n",
    "descriptive_stats_All_DF = no_outliers_dat.describe()\n",
    "\n",
    "# Inspect:\n",
    "descriptive_stats_All_DF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Calculate Descriptive Statistics for Aggregated Columns:\n",
    "\n",
    "Perform descriptive statistics for a group of values. Here, the basic statistics is calculated for different number of cylinders.\n",
    "\n",
    "To do this:\n",
    "- First, the \"features\" list of columns will be selected. This reduces the number of data to analyse.\n",
    "- Next, aggregate the data over the cylinders column with the .agg() method.\n",
    "- The output should be: count, mean and standard deviation over the fuel economy and displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------------+------------------+------------------+-------------------+\n",
      "|Cylinders|Count|           MPG_avg|          Disp_avg|         MPG_stdev|         Disp_stdev|\n",
      "+---------+-----+------------------+------------------+------------------+-------------------+\n",
      "|        3|    1| 8.974491029015983|               2.0|               NaN|                NaN|\n",
      "|        4|    4|21.241497009671995|             2.125| 6.413009924998989|0.24999999999999994|\n",
      "|        5|    1|16.666666666666668|               2.7|               NaN|                NaN|\n",
      "|        6|    5|              22.4|3.1799999999999997|1.5165750888103104|0.26832815729997467|\n",
      "|        8|    4|             18.75|               5.0|               1.5| 0.5477225575051655|\n",
      "|       12|    1|              16.0|               6.0|               NaN|                NaN|\n",
      "+---------+-----+------------------+------------------+------------------+-------------------+"
     ]
    }
   ],
   "source": [
    "(\n",
    "    no_outliers_dat\n",
    "    .select(features)\n",
    "    .groupBy('Cylinders')\n",
    "    .agg(*[\n",
    "        f.count('*').alias('Count'),\n",
    "        f.mean('FuelEconomy').alias('MPG_avg'),\n",
    "        f.mean('Displacement').alias('Disp_avg'),\n",
    "        f.stddev('FuelEconomy').alias('MPG_stdev'),\n",
    "        f.stddev('Displacement').alias('Disp_stdev')\n",
    "        \n",
    "    ])\n",
    "    .orderBy('Cylinders')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "The imputation method applied should be reconsidered as it can be seen to be inaccurate. This is beacuse the \"MPG_avg\" for the 6 cylinder engines are similar to 4 cylinder engines, which should be be the case as it is less efficient.\n",
    "\n",
    "## 8 Computing Correlations on the Data:\n",
    "\n",
    "Features from a dataset that correlates will output an outcome that is more desirable. Note that correlated features amongst themselve can also make the model __unstable__. \n",
    "\n",
    "## 8.1 Correlate between 2 features:\n",
    "\n",
    "To do this, call the .corr() method and input two of the column names. The correlation performed here is the Pearson correlation which is the only one available in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9381829964408109"
     ]
    }
   ],
   "source": [
    "(\n",
    "    no_outliers_dat\n",
    "    .corr('Cylinders', 'Displacement')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These two features highly correlate with each other.\n",
    "\n",
    "## 8.2 Create a Correlation Matrix:\n",
    "\n",
    "This has to be done manually. To do this:\n",
    "- Loop through the list of features.\n",
    "- Compute the pair-wise correlations between these features to fill the upper-triangular portion of the matrix.\n",
    "- The calculated coefficients is appended to the temporary list which gets added onto the correlation list.\n",
    "- Convert this correlation list into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_features = len(features)\n",
    "\n",
    "corr_list = []\n",
    "\n",
    "for i in range(0, nb_features):\n",
    "    temp_list = [None] * i\n",
    "    \n",
    "    for j in range(i, nb_features):\n",
    "        temp_list.append(no_outliers_dat.corr(features[i], features[j]))\n",
    "    corr_list.append( [features[i]] + temp_list )\n",
    "    \n",
    "correlations = spark.createDataFrame(corr_list, ['Column'] + features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Displacement', 1.0, 0.9381829964408109, -0.10757908872387652], ['Cylinders', None, 1.0, -0.04218546545035314], ['FuelEconomy', None, None, 1.0]]"
     ]
    }
   ],
   "source": [
    "# Inpsect the list:\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------------+--------------------+\n",
      "|      Column|Displacement|         Cylinders|         FuelEconomy|\n",
      "+------------+------------+------------------+--------------------+\n",
      "|Displacement|         1.0|0.9381829964408109|-0.10757908872387652|\n",
      "|   Cylinders|        null|               1.0|-0.04218546545035314|\n",
      "| FuelEconomy|        null|              null|                 1.0|\n",
      "+------------+------------+------------------+--------------------+"
     ]
    }
   ],
   "source": [
    "# Inspect the DF:\n",
    "correlations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "There is a strong correlation between Displacement and Cylinders at 0.938, this is because they both define each other in terms of engine sizes. \n",
    "\n",
    "The Fuel Economy is not correlated to both Displacement or Cylinders. This can be because, there are other factors that influences this feature, such as drag or weight of the car. \n",
    "\n",
    "Additionally, if the prediction for this model is for maximum speed of the car, it can be assumed that Displacements and Cylinders would play a larger role than fuel economy. As they also both highly correlate with maximum speed, it is advisable to __only__ use one of them. \n",
    "\n",
    "## 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
