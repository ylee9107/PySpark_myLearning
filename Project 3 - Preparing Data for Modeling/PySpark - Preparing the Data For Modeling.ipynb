{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark - Preparing the Data For Modeling\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project aims to explore the methods for preparing the dataset for modeling purposes. It is important to note that any dataset is dirty until proven otherwise and that it should be proven to be sufficiently clean before using it. However, no dataset can be entirely clean. Below will list some of the problems that can occur in a dataset. Majority of the time, 80% of the work is getting familiar and cleaning up the dataset. The remaining 20% would be building the model.\n",
    "\n",
    "For this project, the dataset used will only consist of 22 records, as this is to get a feel for data cleaning with PySpark and should be transferable to other datasets.\n",
    "\n",
    "## Problems that a Dataset can have:\n",
    "- __Duplicated Observations__: These types of duplication comes from systemic and operator's faults.\n",
    "- __Missing Observations__: These types of errors can come about due to sensor problems, data corruption or unwilling participant that would not provide answers.\n",
    "- __Anomalous Observations__: Observations that stands out when compared to the rest of the dataset. Like Outliers.\n",
    "- __Encoding__: This is when text fields are not normalised, in different languages, gibberish text inputs, or when date and date time fields were not encoded similarly.\n",
    "- __Untrustworthy answers__: These are true when it comes to surveys. When the response is a lie for any number of reasons. This type is much harder to work with and clean up.\n",
    "\n",
    "\n",
    "## Breakdown of this Notebook\n",
    "\n",
    "- Handling Duplicates in data records\n",
    "- Handling missing observations in dataset\n",
    "- Handling outliers\n",
    "- Exploring the descriptive statistics\n",
    "- Computing Correlations\n",
    "- Drawing Histograms to describe the data\n",
    "- Visualising the interactions between features\n",
    "\n",
    "\n",
    "## 1 PySpark Machine Configuration:\n",
    "\n",
    "Here it only uses two processing cores from the CPU, and it set up by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorCores': 4, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\n",
    "    \"executorCores\" : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Setup the Correct Directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the Path:\n",
    "path = '++++your working directory here++++/Datasets/'\n",
    "os.chdir(path)\n",
    "folder_pathway = os.getcwd()\n",
    "\n",
    "# print(folder_pathway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Create the Dataset: 22 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Dirty Dataset:\n",
    "dirty_data = spark.createDataFrame(\n",
    "    [(1,'Porsche','Boxster S','Turbo',2.5,4,22,None),\n",
    "     (2,'Aston Martin','Vanquish','Aspirated',6.0,12,16,None),\n",
    "     (3,'Porsche','911 Carrera 4S Cabriolet','Turbo',3.0,6,24,None),\n",
    "     (3,'General Motors','SPARK ACTIV','Aspirated',1.4,None,32,None),\n",
    "     (5,'BMW','COOPER S HARDTOP 2 DOOR','Turbo',2.0,4,26,None),\n",
    "     (6,'BMW','330i','Turbo',2.0,None,27,None),\n",
    "     (7,'BMW','440i Coupe','Turbo',3.0,6,23,None),\n",
    "     (8,'BMW','440i Coupe','Turbo',3.0,6,23,None),\n",
    "     (9,'Mercedes-Benz',None,None,None,None,27,None),\n",
    "     (10,'Mercedes-Benz','CLS 550','Turbo',4.7,8,21,79231),\n",
    "     (11,'Volkswagen','GTI','Turbo',2.0,4,None,None),\n",
    "     (12,'Ford Motor Company','FUSION AWD','Turbo',2.7,6,20,None),\n",
    "     (13,'Nissan','Q50 AWD RED SPORT','Turbo',3.0,6,22,None),\n",
    "     (14,'Nissan','Q70 AWD','Aspirated',5.6,8,18,None),\n",
    "     (15,'Kia','Stinger RWD','Turbo',2.0,4,25,None),\n",
    "     (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None),\n",
    "     (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None),\n",
    "     (18,'FCA US LLC','300','Aspirated',3.6,6,23,None),\n",
    "     (19,'Hyundai','G80 AWD','Turbo',3.3,6,20,None),\n",
    "     (20,'Hyundai','G80 AWD','Turbo',3.3,6,20,None),\n",
    "     (21,'BMW','X5 M','Turbo',4.4,8,18,121231),\n",
    "     (22,'GE','K1500 SUBURBAN 4WD','Aspirated',5.3,8,18,None) ],\n",
    "    schema = ['Id','Manufacturer','Model','EngineType','Displacement',\n",
    "     'Cylinders','FuelEconomy','MSRP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Id=1, Manufacturer='Porsche', Model='Boxster S', EngineType='Turbo', Displacement=2.5, Cylinders=4, FuelEconomy=22, MSRP=None)]"
     ]
    }
   ],
   "source": [
    "# Inspect:\n",
    "dirty_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Handling duplicates of data records:\n",
    "\n",
    "It can be very hard to spot duplicates of data and these happen all the time. PySpark DataFrame have a method to help remove these duplicates called .dropDuplicates() transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 21)"
     ]
    }
   ],
   "source": [
    "# First is to check for duplicated rows:\n",
    "dirty_data.count(), dirty_data.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From this \"(22, 21)\" output, it can be determined that there is one record of data that has a duplicate.\n",
    "\n",
    "#### To check which record it is:\n",
    "- First, use the .groupBy() function to define which of the dataset columns to aggregate. Here all the columns were chosen.\n",
    "- Next, count the number of times these records occur with the .count() function.\n",
    "- Next, use the .filter() method to select all of the rows in the dataset that occurs more than once.\n",
    "- Lastly, print these records out with the .show() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+\n",
      "| Id|Manufacturer|          Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|count|\n",
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+\n",
      "| 16|      Toyota|CAMRY HYBRID LE| Aspirated|         2.5|        4|         46|null|    2|\n",
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset for duplicates:\n",
    "(\n",
    "    dirty_data\n",
    "    .groupBy(dirty_data.columns)\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that __\"Id 16\"__ is the duplicate record.\n",
    "\n",
    "#### Next is to proceed in removing the duplicate row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove the duplicates:\n",
    "fully_removed_dat = dirty_data.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Duplicates: data IDs\n",
    "\n",
    "If the data is collected over time, it can be possible that the same data would be recorded with diffrent IDs. \n",
    "\n",
    "#### To check for Duplicate IDs:\n",
    "- First groupBy all the columns except for the \"Id\" column.\n",
    "- Next, is to count the number of records.\n",
    "- Next, is to extract the records that has a duplicate count. (\"count > 1\")\n",
    "- Finally, is to print out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+------------+---------+-----------+----+-----+\n",
      "|Manufacturer|     Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|count|\n",
      "+------------+----------+----------+------------+---------+-----------+----+-----+\n",
      "|         BMW|440i Coupe|     Turbo|         3.0|        6|         23|null|    2|\n",
      "|     Hyundai|   G80 AWD|     Turbo|         3.3|        6|         20|null|    2|\n",
      "+------------+----------+----------+------------+---------+-----------+----+-----+"
     ]
    }
   ],
   "source": [
    "# Inspect if the Dataset has duplicate IDs:\n",
    "(\n",
    "    fully_removed_dat\n",
    "    .groupBy( [col for col in fully_removed_dat.columns if col != 'Id'] )\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the count similar to the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 19)"
     ]
    }
   ],
   "source": [
    "# Save the data as a separate copy:\n",
    "no_ids_dat = (\n",
    "    fully_removed_dat\n",
    "    .select( [col for col in fully_removed_dat.columns if col != \"Id\"] )\n",
    ")\n",
    "\n",
    "# Compare the count:\n",
    "no_ids_dat.count(), no_ids_dat.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the output \"(21, 19)\", it shows that there are 4 duplicate records (or 2 duplicate IDs) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19"
     ]
    }
   ],
   "source": [
    "# Remove these duplicates:\n",
    "id_removed_dat = fully_removed_dat.dropDuplicates(\n",
    "    subset = [col for col in fully_removed_dat.columns if col != \"Id\"]\n",
    ")\n",
    "\n",
    "# Count the number of rows:\n",
    "id_removed_dat.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Duplicates: ID Collisions.\n",
    "\n",
    "At this point, after removing duplicates from the previous section, there may still be remaining duplicate IDs that are collisions.\n",
    "\n",
    "These may arise for multiple reasons such as:\n",
    "- Instrumental error\n",
    "- Insufficient data structure to store IDs data\n",
    "- IDs representing some hash function of the record elements\n",
    "- Arising collisions due to choice of hash function.\n",
    "\n",
    "### Import the required Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the dataset has Collisions:\n",
    "\n",
    "Rather than segmenting the operations as in the previous section, here, the code will execute all the required operations in one go.\n",
    "\n",
    "To do this:\n",
    "- Use the .count() method to count all the records that are of non-null values in a specified column.\n",
    "- Next, use the .countDistinct() method to return a distinct count of the vlaues in the specifed column. \n",
    "- Alias both with different names for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CountOfIDs|CountOfDistinctIDs|\n",
      "+----------+------------------+\n",
      "|        19|                18|\n",
      "+----------+------------------+"
     ]
    }
   ],
   "source": [
    "id_removed_dat.agg(\n",
    "    f.count('Id').alias('CountOfIDs'),\n",
    "    f.countDistinct('Id').alias('CountOfDistinctIDs')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, it can be seen that there are 2 records with the same IDs.\n",
    "\n",
    "### Check which IDs are duplicated in the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|count|\n",
      "+---+-----+\n",
      "|  3|    2|\n",
      "+---+-----+"
     ]
    }
   ],
   "source": [
    "(\n",
    "    id_removed_dat\n",
    "    .groupBy('Id')\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here it can be seen that ID 3 has duplicates.\n",
    "\n",
    "## Examine the row that is ID 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------------------+----------+------------+---------+-----------+----+\n",
      "| Id|  Manufacturer|               Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|\n",
      "+---+--------------+--------------------+----------+------------+---------+-----------+----+\n",
      "|  3|General Motors|         SPARK ACTIV| Aspirated|         1.4|     null|         32|null|\n",
      "|  3|       Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|         24|null|\n",
      "+---+--------------+--------------------+----------+------------+---------+-----------+----+"
     ]
    }
   ],
   "source": [
    "(\n",
    "    id_removed_dat\n",
    "    .filter('Id == 3')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here the records are not the same, however, they do share the same ID number (= 3).  To fix this, a new ID should be created that will be unique.\n",
    "\n",
    "### To do this:\n",
    "There is a PySpark SQL function called .monotonically_increasing_id() that will create a unique stream of IDs. \n",
    "\n",
    "Where it will:\n",
    "- Create an alias of the ID column \n",
    "\n",
    "NOTE: this method is good for dataset that are less than 1 billion partitions and the records have to be less than 8 billion recrods in each of the partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+------+\n",
      "|           Id|      Manufacturer|               Model|EngineType|Displacement|Cylinders|FuelEconomy|  MSRP|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+------+\n",
      "|   8589934592|    General Motors|         SPARK ACTIV| Aspirated|         1.4|     null|         32|  null|\n",
      "| 188978561024|     Mercedes-Benz|             CLS 550|     Turbo|         4.7|        8|         21| 79231|\n",
      "| 197568495616|     Mercedes-Benz|                null|      null|        null|     null|         27|  null|\n",
      "| 206158430208|Ford Motor Company|          FUSION AWD|     Turbo|         2.7|        6|         20|  null|\n",
      "| 438086664192|               BMW|COOPER S HARDTOP ...|     Turbo|         2.0|        4|         26|  null|\n",
      "| 523986010112|      Aston Martin|            Vanquish| Aspirated|         6.0|       12|         16|  null|\n",
      "| 721554505728|        Volkswagen|                 GTI|     Turbo|         2.0|        4|       null|  null|\n",
      "| 764504178688|               Kia|         Stinger RWD|     Turbo|         2.0|        4|         25|  null|\n",
      "| 919123001344|               BMW|                330i|     Turbo|         2.0|     null|         27|  null|\n",
      "| 944892805120|           Porsche|           Boxster S|     Turbo|         2.5|        4|         22|  null|\n",
      "| 970662608896|        FCA US LLC|                 300| Aspirated|         3.6|        6|         23|  null|\n",
      "|1030792151040|           Hyundai|             G80 AWD|     Turbo|         3.3|        6|         20|  null|\n",
      "|1039382085632|               BMW|          440i Coupe|     Turbo|         3.0|        6|         23|  null|\n",
      "|1116691496960|            Nissan|   Q50 AWD RED SPORT|     Turbo|         3.0|        6|         22|  null|\n",
      "|1211180777472|               BMW|                X5 M|     Turbo|         4.4|        8|         18|121231|\n",
      "|1331439861760|            Nissan|             Q70 AWD| Aspirated|         5.6|        8|         18|  null|\n",
      "|1606317768704|           Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|         24|  null|\n",
      "|1614907703296|            Toyota|     CAMRY HYBRID LE| Aspirated|         2.5|        4|         46|  null|\n",
      "|1700807049216|                GE|  K1500 SUBURBAN 4WD| Aspirated|         5.3|        8|         18|  null|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+------+"
     ]
    }
   ],
   "source": [
    "# Apply the fix:\n",
    "new_id_dat = (\n",
    "    id_removed_dat\n",
    "    .select(\n",
    "        [f.monotonically_increasing_id().alias('Id')] + \n",
    "        [col for col in id_removed_dat.columns if col != \"Id\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Inspect:\n",
    "new_id_dat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Handling Missing data observations:\n",
    "\n",
    "Missing data can be very common amongst datasets. Here, the dataset used will be \"new_id_dat\" from the previous section.\n",
    "\n",
    "## 5.1 Check the percentage of the data that is Missing:\n",
    "\n",
    "Each row and column will be checked for missing records. From these missing values, it will be determined what data is kept and what will be dropped, or potentially impute.\n",
    "\n",
    "### Calc the number of missing observations in the ROWS:\n",
    "\n",
    "To do this:\n",
    "- It is easier to work with RDDs and loop through each of the element to count the missing values.\n",
    "- First, access the RDD of the new_id_dat DataFrame and proceed with the .map() function.\n",
    "- In the .map() function, loop through each row to extract the 'Id' and count the missing values with \"sum([c == None for c in row])\"\n",
    "- The output of the .map() will be: Id, count of missing values.\n",
    "- Next, select mssing values that has a count of more than 1 with .filter() function.\n",
    "- Next, .collect() these records.\n",
    "- Lastly, create a simple DataFrame using the .orderBy() function to show the records that have missing values and in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|          Id|CountMissing|\n",
      "+------------+------------+\n",
      "|197568495616|           5|\n",
      "|  8589934592|           2|\n",
      "|919123001344|           2|\n",
      "|721554505728|           2|\n",
      "+------------+------------+"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.createDataFrame(\n",
    "        new_id_dat\n",
    "        .rdd\n",
    "        .map(\n",
    "            lambda row: (row['Id'], sum([c == None for c in row]))\n",
    "        )\n",
    "        .filter(lambda el: el[1] > 1)\n",
    "        .collect()\n",
    "        , ['Id', 'CountMissing']\n",
    "    )\n",
    "    .orderBy('CountMissing', ascending=False)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----+----------+------------+---------+-----------+----+\n",
      "|          Id| Manufacturer|Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|\n",
      "+------------+-------------+-----+----------+------------+---------+-----------+----+\n",
      "|197568495616|Mercedes-Benz| null|      null|        null|     null|         27|null|\n",
      "+------------+-------------+-----+----------+------------+---------+-----------+----+"
     ]
    }
   ],
   "source": [
    "# Inspect the records: that have the highest missing values.\n",
    "(\n",
    "    new_id_dat\n",
    "    .where('Id == 197568495616')\n",
    "    .show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above, it can be seen that Mercedes-Benz consists of a lot of Null values.\n",
    "\n",
    "### So, the next step:\n",
    "\n",
    "Would be to remove this record entirely. \n",
    "\n",
    "Note: The 'thresh = 4' is set to only remove records that consists of a minimum of 4 non-missing values. This particular record only has 3 useful pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merc_out = new_id_dat.dropna(thresh = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 18)"
     ]
    }
   ],
   "source": [
    "# Confirm by counts:\n",
    "new_id_dat.count(), merc_out.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----+----------+------------+---------+-----------+----+\n",
      "| Id|Manufacturer|Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|\n",
      "+---+------------+-----+----------+------------+---------+-----------+----+\n",
      "+---+------------+-----+----------+------------+---------+-----------+----+"
     ]
    }
   ],
   "source": [
    "# Inspect if it was really removed: should be a blank DataFrame.\n",
    "(\n",
    "    merc_out\n",
    "    .where('Id == 197568495616')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc the number of missing observations in the Columns:\n",
    "\n",
    "Here, the idea is to check if there are columns with low incidence of relevant information.\n",
    "\n",
    "To do this:\n",
    "- First, for the inner list that is \"(1 - (f.count(c) / f.count('*'))).alias(c + '_miss')\" and \"for c in merc_out.columns\", this is where a loop is used to go through all the columns in the merc_out DF, followed by a count on the number of non-missing values to be found in each of the columns. Next, is dividing it by the total count of all the rows. Then followed by subtracting this from 1, to get the percentage of missing values.\n",
    "\n",
    "   func can be seen as -> ( *[ (1 - (f.count(c) / f.count('*'))).alias(c + '_miss') for c in merc_out.columns] )\n",
    "   \n",
    "- Note, that no calc. is done yet as Python only stores the information as lists of objects/pointers. When the .agg() function is called, then it gets translated into PySpark's internal execution graph, and only gets executed once the .collect() action is called and executed.\n",
    "- The .collect() function will return a list of one element, that is a Row() object with aggregated information.\n",
    "- These Row() objects are then converted in dictionaries by using the .asDict() first before the items can be extracted by using the .items() functions. The results from this will be a list of tuples. \n",
    "- This list of tuples will have two elements, where the first one is the \"column name\" which is appened with \"_miss\" by use of the .alias() function. The second element is the percentage of the missing observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRP_miss 0.8888888888888888\n",
      "Cylinders_miss 0.11111111111111116\n",
      "FuelEconomy_miss 0.05555555555555558\n",
      "Id_miss 0.0\n",
      "Manufacturer_miss 0.0\n",
      "Model_miss 0.0\n",
      "EngineType_miss 0.0\n",
      "Displacement_miss 0.0"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(\n",
    "    merc_out\n",
    "    .agg(*[\n",
    "        (1 - (f.count(c) / f.count('*'))).alias(c + '_miss')\n",
    "        for c in merc_out.columns\n",
    "    ])\n",
    "    .collect()[0]\n",
    "    .asDict()\n",
    "    .items()\n",
    "    , key = lambda el: el[1]\n",
    "    , reverse = True\n",
    "):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRP_miss 0.8888888888888888\n",
      "Cylinders_miss 0.11111111111111116\n",
      "FuelEconomy_miss 0.05555555555555558\n",
      "Id_miss 0.0\n",
      "Manufacturer_miss 0.0\n",
      "Model_miss 0.0\n",
      "EngineType_miss 0.0\n",
      "Displacement_miss 0.0"
     ]
    }
   ],
   "source": [
    "# Another way to represent the above is:\n",
    "\n",
    "data = merc_out.agg(*[(1 - (f.count(c) / f.count('*'))).alias(c + '_miss') for c in merc_out.columns]).collect()[0].asDict().items()\n",
    "\n",
    "for k, v in sorted( data, key = lambda el: el[1], reverse = True ):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above, it can be seen that the MSRP column has a lot of missing values (at 88%). Therefore, this column can be dropped, as it provides no useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+\n",
      "|           Id|      Manufacturer|               Model|EngineType|Displacement|Cylinders|FuelEconomy|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+\n",
      "|   8589934592|    General Motors|         SPARK ACTIV| Aspirated|         1.4|     null|         32|\n",
      "| 188978561024|     Mercedes-Benz|             CLS 550|     Turbo|         4.7|        8|         21|\n",
      "| 206158430208|Ford Motor Company|          FUSION AWD|     Turbo|         2.7|        6|         20|\n",
      "| 438086664192|               BMW|COOPER S HARDTOP ...|     Turbo|         2.0|        4|         26|\n",
      "| 523986010112|      Aston Martin|            Vanquish| Aspirated|         6.0|       12|         16|\n",
      "| 721554505728|        Volkswagen|                 GTI|     Turbo|         2.0|        4|       null|\n",
      "| 764504178688|               Kia|         Stinger RWD|     Turbo|         2.0|        4|         25|\n",
      "| 919123001344|               BMW|                330i|     Turbo|         2.0|     null|         27|\n",
      "| 944892805120|           Porsche|           Boxster S|     Turbo|         2.5|        4|         22|\n",
      "| 970662608896|        FCA US LLC|                 300| Aspirated|         3.6|        6|         23|\n",
      "|1030792151040|           Hyundai|             G80 AWD|     Turbo|         3.3|        6|         20|\n",
      "|1039382085632|               BMW|          440i Coupe|     Turbo|         3.0|        6|         23|\n",
      "|1116691496960|            Nissan|   Q50 AWD RED SPORT|     Turbo|         3.0|        6|         22|\n",
      "|1211180777472|               BMW|                X5 M|     Turbo|         4.4|        8|         18|\n",
      "|1331439861760|            Nissan|             Q70 AWD| Aspirated|         5.6|        8|         18|\n",
      "|1606317768704|           Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|         24|\n",
      "|1614907703296|            Toyota|     CAMRY HYBRID LE| Aspirated|         2.5|        4|         46|\n",
      "|1700807049216|                GE|  K1500 SUBURBAN 4WD| Aspirated|         5.3|        8|         18|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+-----------+"
     ]
    }
   ],
   "source": [
    "# Drop the column \"MSRP\":\n",
    "no_MSRP = merc_out.select( [col for col in new_id_dat.columns if col != 'MSRP'] )\n",
    "\n",
    "# Inspect:\n",
    "no_MSRP.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Imputing the missing observations:\n",
    "\n",
    "This means the replacement of missing data with substituted values.\n",
    "\n",
    "There are __two__ ways to solve this:\n",
    "- One, Pass a value that every \"Null\" or \"None\" in the dataset will be replaced with.\n",
    "- Two, Pass a dictionary with different values in it for each of the column with missing records.\n",
    "\n",
    "In this example, the 2nd approach will be used. \n",
    "\n",
    "#### To do this: Specify a Ratio between the Fuel Economy and Displacement | Number of cyclinders and displacement.\n",
    "\n",
    "The formulas used to do these are the following:\n",
    "\n",
    "- To replace the missing values in the fuel economy -> \n",
    "    fuel_economy_mult = fuel_economy / (displacement * cylinders)\n",
    "    \n",
    "- To replace the missing calues in number of cylinders -> \n",
    "    cylinders_mult = cylinders / displacement\n",
    "\n",
    "These multipliers will be applied onto each row and taken as the average of these.\n",
    "    \n",
    "NOTE: these are not going to be accurate but serves the purpose. \n",
    "\n",
    "Once the formulas are applied, a dictionary can be created in Spark DataFrame is to use the .toPandss() function to convert the Spark DF to Pandas DF. This is then followed by a .to_dict() function to convert the data to a dictionary as proposed as the 2nd approach. \n",
    "\n",
    "The paramter that is \"records\" in the .to_dict() function, willcovert each row to a dictionary, where the key is the column name with the corresponding record value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Applying the formulas and create a Dictionary:\n",
    "\n",
    "multipliers_dict = (\n",
    "    no_MSRP\n",
    "    .agg(\n",
    "        f.mean(\n",
    "            f.col('FuelEconomy') / (f.col('Displacement') * f.col('Cylinders'))\n",
    "        ).alias('FuelEconomy'),\n",
    "        f.mean(\n",
    "            f.col('Cylinders') / f.col('Displacement')\n",
    "        ).alias('Cylinders')\n",
    "    )\n",
    ").toPandas().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FuelEconomy': 1.4957485048359973, 'Cylinders': 1.8353365984789105}"
     ]
    }
   ],
   "source": [
    "# Inspect:\n",
    "multipliers_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute the Dataset with the created Dictionary above:\n",
    "\n",
    "To do this:\n",
    "- First, convert the original data to reflect the ratios specified earlier.\n",
    "- Apply the multipliers_dict to fill in the missing values in the data.\n",
    "- Lastly, revert the columns back to their orignal state.\n",
    "\n",
    "The .withColumn() function overwrites the origninal column names.\n",
    "\n",
    "Source: https://sparkbyexamples.com/spark/spark-dataframe-withcolumn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputed_dat = (\n",
    "    no_MSRP\n",
    "    .withColumn('FuelEconomy', f.col('FuelEconomy') / f.col('Displacement') / f.col('Cylinders'))\n",
    "    .withColumn('Cylinders', f.col('Cylinders') / f.col('Displacement'))\n",
    "    .fillna(multipliers_dict)\n",
    "    .withColumn('Cylinders', (f.col('Cylinders') * f.col('Displacement')).cast('integer') )\n",
    "    .withColumn('FuelEconomy', f.col('FuelEconomy') * f.col('Displacement') * f.col('Cylinders'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+\n",
      "|           Id|      Manufacturer|               Model|EngineType|Displacement|Cylinders|       FuelEconomy|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+\n",
      "|   8589934592|    General Motors|         SPARK ACTIV| Aspirated|         1.4|        2| 4.188095813540793|\n",
      "| 188978561024|     Mercedes-Benz|             CLS 550|     Turbo|         4.7|        8|              21.0|\n",
      "| 206158430208|Ford Motor Company|          FUSION AWD|     Turbo|         2.7|        5|16.666666666666668|\n",
      "| 438086664192|               BMW|COOPER S HARDTOP ...|     Turbo|         2.0|        4|              26.0|\n",
      "| 523986010112|      Aston Martin|            Vanquish| Aspirated|         6.0|       12|              16.0|\n",
      "| 721554505728|        Volkswagen|                 GTI|     Turbo|         2.0|        4|11.965988038687978|\n",
      "| 764504178688|               Kia|         Stinger RWD|     Turbo|         2.0|        4|              25.0|\n",
      "| 919123001344|               BMW|                330i|     Turbo|         2.0|        3| 8.974491029015983|\n",
      "| 944892805120|           Porsche|           Boxster S|     Turbo|         2.5|        4|              22.0|\n",
      "| 970662608896|        FCA US LLC|                 300| Aspirated|         3.6|        6|              23.0|\n",
      "|1030792151040|           Hyundai|             G80 AWD|     Turbo|         3.3|        6|              20.0|\n",
      "|1039382085632|               BMW|          440i Coupe|     Turbo|         3.0|        6|23.000000000000004|\n",
      "|1116691496960|            Nissan|   Q50 AWD RED SPORT|     Turbo|         3.0|        6|21.999999999999996|\n",
      "|1211180777472|               BMW|                X5 M|     Turbo|         4.4|        8|              18.0|\n",
      "|1331439861760|            Nissan|             Q70 AWD| Aspirated|         5.6|        8|              18.0|\n",
      "|1606317768704|           Porsche|911 Carrera 4S Ca...|     Turbo|         3.0|        6|              24.0|\n",
      "|1614907703296|            Toyota|     CAMRY HYBRID LE| Aspirated|         2.5|        4|              46.0|\n",
      "|1700807049216|                GE|  K1500 SUBURBAN 4WD| Aspirated|         5.3|        8|              18.0|\n",
      "+-------------+------------------+--------------------+----------+------------+---------+------------------+"
     ]
    }
   ],
   "source": [
    "# Inspect the DF:\n",
    "imputed_dat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The resulting values found in the cylinders and fuel economy columns are not completely accurate, however, they aare still better than just replacing them with predefined values.\n",
    "\n",
    "\n",
    "## 6 Handling Outliers in the Dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
