{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark - Preparing the Data For Modeling\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project aims to explore the methods for preparing the dataset for modeling purposes. It is important to note that any dataset is dirty until proven otherwise and that it should be proven to be sufficiently clean before using it. However, no dataset can be entirely clean. Below will list some of the problems that can occur in a dataset. Majority of the time, 80% of the work is getting familiar and cleaning up the dataset. The remaining 20% would be building the model.\n",
    "\n",
    "For this project, the dataset used will only consist of 22 records, as this is to get a feel for data cleaning with PySpark and should be transferable to other datasets.\n",
    "\n",
    "## Problems that a Dataset can have:\n",
    "- __Duplicated Observations__: These types of duplication comes from systemic and operator's faults.\n",
    "- __Missing Observations__: These types of errors can come about due to sensor problems, data corruption or unwilling participant that would not provide answers.\n",
    "- __Anomalous Observations__: Observations that stands out when compared to the rest of the dataset. Like Outliers.\n",
    "- __Encoding__: This is when text fields are not normalised, in different languages, gibberish text inputs, or when date and date time fields were not encoded similarly.\n",
    "- __Untrustworthy answers__: These are true when it comes to surveys. When the response is a lie for any number of reasons. This type is much harder to work with and clean up.\n",
    "\n",
    "\n",
    "## Breakdown of this Notebook\n",
    "\n",
    "- Handling Duplicates in data records\n",
    "- Handling missing observations in dataset\n",
    "- Handling outliers\n",
    "- Exploring the descriptive statistics\n",
    "- Computing Correlations\n",
    "- Drawing Histograms to describe the data\n",
    "- Visualising the interactions between features\n",
    "\n",
    "\n",
    "## 1 PySpark Machine Configuration:\n",
    "\n",
    "Here it only uses two processing cores from the CPU, and it set up by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorCores': 4, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\n",
    "    \"executorCores\" : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Setup the Correct Directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the Path:\n",
    "path = '++++your working directory here++++/Datasets/'\n",
    "os.chdir(path)\n",
    "folder_pathway = os.getcwd()\n",
    "\n",
    "# print(folder_pathway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Create the Dataset: 22 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Dirty Dataset:\n",
    "dirty_data = spark.createDataFrame(\n",
    "    [(1,'Porsche','Boxster S','Turbo',2.5,4,22,None),\n",
    "     (2,'Aston Martin','Vanquish','Aspirated',6.0,12,16,None),\n",
    "     (3,'Porsche','911 Carrera 4S Cabriolet','Turbo',3.0,6,24,None),\n",
    "     (3,'General Motors','SPARK ACTIV','Aspirated',1.4,None,32,None),\n",
    "     (5,'BMW','COOPER S HARDTOP 2 DOOR','Turbo',2.0,4,26,None),\n",
    "     (6,'BMW','330i','Turbo',2.0,None,27,None),\n",
    "     (7,'BMW','440i Coupe','Turbo',3.0,6,23,None),\n",
    "     (8,'BMW','440i Coupe','Turbo',3.0,6,23,None),\n",
    "     (9,'Mercedes-Benz',None,None,None,None,27,None),\n",
    "     (10,'Mercedes-Benz','CLS 550','Turbo',4.7,8,21,79231),\n",
    "     (11,'Volkswagen','GTI','Turbo',2.0,4,None,None),\n",
    "     (12,'Ford Motor Company','FUSION AWD','Turbo',2.7,6,20,None),\n",
    "     (13,'Nissan','Q50 AWD RED SPORT','Turbo',3.0,6,22,None),\n",
    "     (14,'Nissan','Q70 AWD','Aspirated',5.6,8,18,None),\n",
    "     (15,'Kia','Stinger RWD','Turbo',2.0,4,25,None),\n",
    "     (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None),\n",
    "     (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None),\n",
    "     (18,'FCA US LLC','300','Aspirated',3.6,6,23,None),\n",
    "     (19,'Hyundai','G80 AWD','Turbo',3.3,6,20,None),\n",
    "     (20,'Hyundai','G80 AWD','Turbo',3.3,6,20,None),\n",
    "     (21,'BMW','X5 M','Turbo',4.4,8,18,121231),\n",
    "     (22,'GE','K1500 SUBURBAN 4WD','Aspirated',5.3,8,18,None) ],\n",
    "    schema = ['Id','Manufacturer','Model','EngineType','Displacement',\n",
    "     'Cylinders','FuelEconomy','MSRP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Id=1, Manufacturer='Porsche', Model='Boxster S', EngineType='Turbo', Displacement=2.5, Cylinders=4, FuelEconomy=22, MSRP=None)]"
     ]
    }
   ],
   "source": [
    "# Inspect:\n",
    "dirty_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Handling duplicates of data records:\n",
    "\n",
    "It can be very hard to spot duplicates of data and these happen all the time. PySpark DataFrame have a method to help remove these duplicates called .dropDuplicates() transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 21)"
     ]
    }
   ],
   "source": [
    "# First is to check for duplicated rows:\n",
    "dirty_data.count(), dirty_data.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From this \"(22, 21)\" output, it can be determined that there is one record of data that has a duplicate.\n",
    "\n",
    "#### To check which record it is:\n",
    "- First, use the .groupBy() function to define which of the dataset columns to aggregate. Here all the columns were chosen.\n",
    "- Next, count the number of times these records occur with the .count() function.\n",
    "- Next, use the .filter() method to select all of the rows in the dataset that occurs more than once.\n",
    "- Lastly, print these records out with the .show() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+\n",
      "| Id|Manufacturer|          Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|count|\n",
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+\n",
      "| 16|      Toyota|CAMRY HYBRID LE| Aspirated|         2.5|        4|         46|null|    2|\n",
      "+---+------------+---------------+----------+------------+---------+-----------+----+-----+"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset for duplicates:\n",
    "(\n",
    "    dirty_data\n",
    "    .groupBy(dirty_data.columns)\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that __\"Id 16\"__ is the duplicate record.\n",
    "\n",
    "#### Next is to proceed in removing the duplicate row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove the duplicates:\n",
    "fully_removed_dat = dirty_data.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Duplicates: data IDs\n",
    "\n",
    "If the data is collected over time, it can be possible that the same data would be recorded with diffrent IDs. \n",
    "\n",
    "#### To check for Duplicate IDs:\n",
    "- First groupBy all the columns except for the \"Id\" column.\n",
    "- Next, is to count the number of records.\n",
    "- Next, is to extract the records that has a duplicate count. (\"count > 1\")\n",
    "- Finally, is to print out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+------------+---------+-----------+----+-----+\n",
      "|Manufacturer|     Model|EngineType|Displacement|Cylinders|FuelEconomy|MSRP|count|\n",
      "+------------+----------+----------+------------+---------+-----------+----+-----+\n",
      "|         BMW|440i Coupe|     Turbo|         3.0|        6|         23|null|    2|\n",
      "|     Hyundai|   G80 AWD|     Turbo|         3.3|        6|         20|null|    2|\n",
      "+------------+----------+----------+------------+---------+-----------+----+-----+"
     ]
    }
   ],
   "source": [
    "# Inspect if the Dataset has duplicate IDs:\n",
    "(\n",
    "    fully_removed_dat\n",
    "    .groupBy( [col for col in fully_removed_dat.columns if col != 'Id'] )\n",
    "    .count()\n",
    "    .filter('count > 1')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the count similar to the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 19)"
     ]
    }
   ],
   "source": [
    "# Save the data as a separate copy:\n",
    "no_ids_dat = (\n",
    "    fully_removed_dat\n",
    "    .select( [col for col in fully_removed_dat.columns if col != \"Id\"] )\n",
    ")\n",
    "\n",
    "# Compare the count:\n",
    "no_ids_dat.count(), no_ids_dat.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the output \"(21, 19)\", it shows that there are 4 duplicate records (or 2 duplicate IDs) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19"
     ]
    }
   ],
   "source": [
    "# Remove these duplicates:\n",
    "id_removed_dat = fully_removed_dat.dropDuplicates(\n",
    "    subset = [col for col in fully_removed_dat.columns if col != \"Id\"]\n",
    ")\n",
    "\n",
    "# Count the number of rows:\n",
    "id_removed_dat.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Duplicates: ID Collisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
