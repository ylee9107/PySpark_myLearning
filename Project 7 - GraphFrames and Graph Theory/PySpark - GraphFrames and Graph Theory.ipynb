{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark - GraphFrames and Graph Theory\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Sometimes, it can be difficult to explain or better comprehend certain types of dataset or data problems with just a simple distribution charts, pie charts or scatter plots. These kinds of dataset can consists of geographical data points, social networks or user interactions. This is where graphs that consists of 3 components that are edges, nodes (or vertices) and their properties are utilised to represent these kinds of data problems in a more intuitive and easier way for comprehension. The ability to simply assign nodes to anything and define their relationship (between these nodes) with edges provides a great amount of flexibility to represent the data in a different way. This can also means that it is possible to connect two seemingly disparate graphs into a common graph, as long as there is a link that can be found between the nodes of the two disparate graphs. For example, joining a social network with restaurant reccomendations, number of travellers and airport delays etc.\n",
    "\n",
    "For more information:\n",
    "- https://www.geeksforgeeks.org/mathematics-graph-theory-basics-set-1/\n",
    "- http://www.analytictech.com/mb021/graphtheory.htm\n",
    "\n",
    "## Breakdown of this Notebook\n",
    "\n",
    "- An Introduction to Graph Theory and GraphFrames for Apache Spark\n",
    "- Installing GraphFrames\n",
    "- Data Preparation\n",
    "- Building the Graph\n",
    "- Running querries against the graph\n",
    "- Understanding the Graph\n",
    "- Utilise PageRank to determine airport ranks\n",
    "- Finding the fewest number of connections (flights)\n",
    "- Visualising the Graph.\n",
    "\n",
    "## Why use GraphFrames with Spark?\n",
    "\n",
    "One of the main problems that persist when designing and computing graphs is that the traversal and computation of these graphing algorithms are ofthen computationally expensive and at times can be very slow. To overcome this, GraphFrams with Apache Spark is able to take advantage of the performance inherent of the DataFrames where it is distributed. \n",
    "\n",
    "### Under the hood of Graphframes:\n",
    "\n",
    "GraphFrames utilises two Spark DataFrames where one would be used for the nodes and another for the edges, it leverages the optimisations and simplicity of the DataFrame API and in addition, it can be used and interacted with by other programming languages such as Python, Java and Scala APIs.\n",
    "\n",
    "## Datasets:\n",
    "\n",
    "The datasets for this project are the (1) Airline On-Time Performance and Causes of Flight Delays data which consists of information about scheduled and actual departure/arrival times along with the delay causes, and (2) OpenFlights data which details the airport and airlines. More details can be found in the link below.\n",
    "\n",
    "The Datasets are obtained from:\n",
    "- https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data\n",
    "- https://openflights.org/data.html\n",
    "\n",
    "Or download the folder from this repository which should contain the following files:\n",
    "- airport-codes-na.txt\n",
    "- departuredelays.csv\n",
    "\n",
    "## 1 Installing GraphFrames:\n",
    "\n",
    "GraphFrames Spark package can be found at the link: https://spark-packages.org/package/graphframes/graphframes. Where it uses PySpark to download the latest version, compile it and execute it within the context of the Spark Job.\n",
    "\n",
    "At the time of writing this Notebook, the command was:\n",
    "\n",
    "> $SPARK_HOME/bin/spark-shell --packages graphframes:graphframes:0.8.0-spark3.0-s_2.12\n",
    "\n",
    "To install:\n",
    "1. In a Terminal Window, after activating your PySpark Environment, type in \"cd /your spark installed location/bin.\n",
    "    - In my case it was \"cd /opt/spark/bin\n",
    "2. Then type in: spark-shell --packages graphframes:graphframes:0.8.0-spark3.0-s_2.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 PySpark Machine Configuration:\n",
    "\n",
    "Here it only uses four processing cores from the CPU, and it set up by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure\n",
    "{\n",
    "    \"executorCores\" : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Setup the Correct Directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the Path:\n",
    "path = '++++your working directory here++++/Datasets/'\n",
    "os.chdir(path)\n",
    "folder_pathway = os.getcwd()\n",
    "\n",
    "# print(folder_pathway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Example of Nodes and Edges in Graphs:\n",
    "\n",
    "The diagram below details the nodes and edges in a graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "# Import the required library and set to use ggplot:\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "folder_pathway = os.getcwd()\n",
    "image_path = folder_pathway + \"/Description Images/\"\n",
    "\n",
    "# plot the image\n",
    "fig, ax1 = plt.subplots(figsize=(16,10))\n",
    "image = mpimg.imread(image_path + 'Example Graph Theory.png')\n",
    "plt.imshow(image);\n",
    "\n",
    "print('Image source -> https://www.geeksforgeeks.org/mathematics-graph-theory-basics-set-1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "# plot the image\n",
    "fig, ax1 = plt.subplots(figsize=(16, 10))\n",
    "image = mpimg.imread(image_path + 'Microbatch lines of DStream.png')\n",
    "plt.imshow(image);\n",
    "\n",
    "print('Image source -> ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
